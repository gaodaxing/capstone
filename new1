suppressWarnings(library(tm))
suppressWarnings(library(RWeka))
##library(rJava)
library(SnowballC)
path='C:\\Users\\Daxing\\Documents\\final\\en_US'
path1=file.path(path,"en_US.blogs.txt")
path2=file.path(path,"en_US.news.txt")
path3=file.path(path,"en_US.twitter.txt")
fh1=file(path1,open="r")
fh2=file(path2,open="r")
fh3=file(path3,open="r")

F1=readLines(fh1,warn=F)
F1=sample(F1,as.integer(NROW(F1)*0.15),replace=F)
close(fh1)
F1=iconv(F1,"latin1", "ASCII", sub="")
#F1=iconv(F1,to="UTF-8-MAC",sub="")
F2=readLines(fh2,warn=F)
F2=sample(F2,as.integer(NROW(F2)*0.15),replace=F)
#F2=iconv(F2,to="UTF-8-MAC",sub="")
close(fh2)
F2=iconv(F2,"latin1", "ASCII", sub="")
F3=readLines(fh3,warn=F)
F3=sample(F3,as.integer(NROW(F3)*0.15),replace=F)
close(fh3)
F3=iconv(F3,"latin1", "ASCII", sub="")##remove emoji from twitter
#F3=iconv(F3,to="UTF-8-MAC",sub="")

unifreq=NULL
bifreq=NULL
trifreq=NULL

for (i in 1:125){
  cat("This is the ",i,"th corpus\n")
  t=Sys.time()
  f1=F1[as.integer((NROW(F1)*0.004*(i-1))+1):as.integer(NROW(F1)*0.004*i)]
  f2=F2[as.integer((NROW(F2)*0.004*(i-1))+1):as.integer(NROW(F2)*0.004*i)]
  f3=F3[as.integer((NROW(F3)*0.004*(i-1))+1):as.integer(NROW(F3)*0.004*i)]
  
  docs=Corpus(VectorSource(c(f1,f2,f3)))
  docs=tm_map(docs,content_transformer(tolower))
  docs=tm_map(docs,removePunctuation)
  docs=tm_map(docs, removeNumbers)
  docs=tm_map(docs,stripWhitespace)
  docs=tm_map(docs,removeWords,stopwords("english"))
  ##docs=tm_map(docs, stemDocument)
  docs=tm_map(docs,PlainTextDocument)
  
  UnigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))##build unigram
  BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))##build bigram
  TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))##build trigram
  
  tdm1<-TermDocumentMatrix(docs,control = list(tokenize=UnigramTokenizer))
  tdm1=removeSparseTerms(tdm1,.9999)##remove sparse term
  tdm1m<-as.matrix(tdm1)
  tdm1_hf=as.data.frame(cbind(name=row.names(tdm1),Frequency=rowSums(tdm1m)))
  unifreq=rbind(unifreq,tdm1_hf)
  unifreq$Frequency=as.numeric(unifreq$Frequency)#calculate unigram frequency
  unifreq=aggregate(Frequency~name,unifreq,FUN=sum)
  
  
  tdm2<-TermDocumentMatrix(docs,control = list(tokenize=BigramTokenizer))
  tdm2=removeSparseTerms(tdm2,.9999)##remove sparse term
  tdm2m<-as.matrix(tdm2)
  tdm2_hf=as.data.frame(cbind(name=row.names(tdm2),Frequency=rowSums(tdm2m)))
  bifreq=rbind(bifreq,tdm2_hf)
  bifreq$Frequency=as.numeric(bifreq$Frequency)#calculate unigram frequency
  bifreq=aggregate(Frequency~name,bifreq,FUN=sum)
  
  tdm3<-TermDocumentMatrix(docs,control = list(tokenize=TrigramTokenizer))
  tdm3=removeSparseTerms(tdm3,.9999)##remove sparse term
  tdm3m<-as.matrix(tdm3)
  tdm3_hf=as.data.frame(cbind(name=row.names(tdm3),Frequency=rowSums(tdm3m)))
  trifreq=rbind(trifreq,tdm3_hf)
  trifreq$Frequency=as.numeric(trifreq$Frequency)#calculate unigram frequency
  trifreq=aggregate(Frequency~name,trifreq,FUN=sum)
  
  print(Sys.time()-t)
  write.csv(unifreq,"uni.csv")
  write.csv(bifreq,"bi.csv")
  write.csv(trifreq,"tri.csv")
  
}
